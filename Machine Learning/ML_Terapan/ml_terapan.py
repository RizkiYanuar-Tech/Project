# -*- coding: utf-8 -*-
"""ML_Terapan.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IH-Ft_eAsDOWgSl5ap4Spoi5IVatUlbg

# **Library**
"""

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np
from sklearn.preprocessing import OneHotEncoder, LabelEncoder
from sklearn.model_selection import learning_curve
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, ConfusionMatrixDisplay

"""# **Import Dataset**"""

loanDF = pd.read_csv('https://raw.githubusercontent.com/RizkiYanuar-Tech/Submission_ML_Terapan/refs/heads/main/loan_data.csv')

loanDF

loanDF.info()

loanDF.describe()

"""## **Data visualization**"""

plt.figure(figsize=(10, 4))  # Tambahkan ukuran figure agar tidak dempet

# Subplot 1 - Education
plt.subplot(1, 3, 1)
plt.bar(loanDF['person_education'].value_counts().index,
        loanDF['person_education'].value_counts())
plt.title("Education")
plt.xticks(rotation=45)

# Subplot 2 - Loan Intent
plt.subplot(1, 3, 2)
plt.bar(loanDF['loan_intent'].value_counts().index,
        loanDF['loan_intent'].value_counts())
plt.title("Loan Intent")
plt.xticks(rotation=45)

# Subplot 3 - Home Ownership
plt.subplot(1, 3, 3)
plt.bar(loanDF['person_home_ownership'].value_counts().index,
        loanDF['person_home_ownership'].value_counts())
plt.title("Home Ownership")
plt.xticks(rotation=45)

plt.tight_layout()
plt.show()

"""# **Data Preprocessing**

### **Encoding**
"""

OH = OneHotEncoder(sparse_output=False, categories=[['female','male']])

loanDF['person_gender'] = OH.fit_transform(loanDF[['person_gender']])

le = LabelEncoder()

loanDF['person_education'] = le.fit_transform(loanDF['person_education'])
loanDF['person_home_ownership'] = le.fit_transform(loanDF['person_home_ownership'])
loanDF['loan_intent'] = le.fit_transform(loanDF['loan_intent'])
loanDF['previous_loan_defaults_on_file'] = le.fit_transform(loanDF['previous_loan_defaults_on_file'])

loanDF.head()

"""### **Check Outliers**"""

plt.figure(figsize=(10, 4))
plt.title("Outlier loan_amnt")
sns.boxplot(data=loanDF, x='loan_amnt')

plt.figure(figsize=(10, 4))
plt.title("Outlier loan_int_rate")
sns.boxplot(data=loanDF, x='loan_int_rate')

plt.figure(figsize=(10, 4))
plt.title("Outlier loan_percent_income")
sns.boxplot(data=loanDF, x='loan_percent_income')

plt.figure(figsize=(10, 4))
plt.title("Outlier Credit_Score")
sns.boxplot(data=loanDF, x='credit_score')

"""### **Analisa**

Pada dataset tidak ditemukan adanya missing value ataupun duplikat data, kemudian dilakukan encoding kepada label kategorik, sehingga model dapat memahami isi data melalui bentuk numerik. Kemudian dilakukan pengecheckan outlier pada data, karena jika outlier dibiarkan bisa mempengaruhi kinerja model

# **Data Cleaning**

### **Cleaning Outliers**
"""

Q1 = loanDF['loan_amnt'].quantile(0.25)
Q3 = loanDF['loan_amnt'].quantile(0.75)
IQR = Q3 - Q1

lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

loanDF = loanDF[(loanDF['loan_amnt'] >= lower_bound) & (loanDF['loan_amnt'] <= upper_bound)]

plt.figure(figsize=(10, 4))
plt.title("Outlier loan_amnt")
sns.boxplot(data=loanDF, x='loan_amnt')

Q1 = loanDF['loan_int_rate'].quantile(0.25)
Q3 = loanDF['loan_int_rate'].quantile(0.75)
IQR = Q3 - Q1

lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

loanDF = loanDF[(loanDF['loan_int_rate'] >= lower_bound) & (loanDF['loan_int_rate'] <= upper_bound)]

plt.figure(figsize=(10, 4))
plt.title("Outlier loan_int_rate")
sns.boxplot(data=loanDF, x='loan_int_rate')

Q1 = loanDF['loan_percent_income'].quantile(0.25)
Q3 = loanDF['loan_percent_income'].quantile(0.75)
IQR = Q3 - Q1

lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

loanDF = loanDF[(loanDF['loan_percent_income'] >= lower_bound) & (loanDF['loan_percent_income'] <= upper_bound)]

plt.figure(figsize=(10, 4))
plt.title("Outlier loan_percent_income")
sns.boxplot(data=loanDF, x='loan_percent_income')

Q1 = loanDF['credit_score'].quantile(0.25)
Q3 = loanDF['credit_score'].quantile(0.75)
IQR = Q3 - Q1

lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

loanDF = loanDF[(loanDF['credit_score'] >= lower_bound) & (loanDF['credit_score'] <= upper_bound)]

plt.figure(figsize=(10, 4))
plt.title("Outlier credit_score")
sns.boxplot(data=loanDF, x='credit_score')

"""## **Analisa**

Dilakukan pembersihan data outlier pada kolom numerik menggunakan teknik capping, dimana nilai yang melebihi batas atas, dan batas bawah akan diubah sesuai dengan nilai di batas atas dan batas bawah

# **Bivariate Analysis**
"""

numeric_loanDF = loanDF.select_dtypes(include=['int64','float64'])

correlation_matrix = numeric_loanDF.corr()

plt.figure(figsize=(15,15))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)
plt.title('Correlation Matrix')
plt.show()

"""**Analisa**

Ditemukan bahwa terdapat hubungan sangat kuat antara **lama riwayat kredit** dan **juga umur pengguna**, hubungan antara **lama riwayat kredit** dan juga **pengalaman bekerja**, kemudian hubungan antara **pengalaman bekerja** dan **umur**. Kemudian terdapat hubungan cukup kuat antara **persentase jumlah pinjaman** dengan **total pinjaman yang diminta**
"""

plt.figure(figsize=(10, 4))
plt.title("Correlation loan_amnt and loan_int_rate")
sns.scatterplot(data=loanDF, x='person_age', y='cb_person_cred_hist_length', hue='loan_status')
plt.show()

"""**Analisa**

Ada korelasi positif yang jelas antara usia dan lama riwayat kredit, dimana peminjam dengan rentang usia 30-60 tahun yang memiliki lama histori kredit yang sedang cenderung memiliki peluang disetujui pinjaman lebih besar
"""

plt.figure(figsize=(10,5))
plt.title("Correlation Pengalaman bekerja dan lama riwayat kredit")
sns.scatterplot(data=loanDF, x='person_emp_exp', y='cb_person_cred_hist_length', hue='loan_status')
plt.show()

"""**Analisa**

Terdapat korelasi positif dimana orang yang memiliki pengalaman bekerja lebih lama cenderung memiliki riwayat kredit yang lama, orang yang memiliki pengalaman bekerja dengan rentang 0 - 25 tahun dan memiliki riwayat kredit dengan rentang 10 - 25 tahun cenderung memiliki peluang disetujui lebih besar
"""

plt.figure(figsize=(10, 4))
plt.title("Correlation loan_amnt and loan_percent_income")
sns.scatterplot(data=loanDF, x='loan_amnt', y='loan_percent_income', hue='loan_status')
plt.show()

"""**Analisa**

Tidak ditemukan korelasi yang kuat antara jumlah pinjaman dengan persentase pendapatan, tetapi disimpulkan bahwa peminjaman disetujui jika pinjaman yang diajukan jumlahnya tidak terlalu besar dibandingkan pendapatan orang tersebut

# **Splitting Dataset**
"""

X = loanDF.drop('loan_status', axis=1)
Y = loanDF['loan_status']

X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

"""## **Analisa**

Dilakukan pembagian dataset menjadi data train dan test dengan proporsi 80:20

# **Model Klasifikasi**

## **RandomForest**
"""

#Inisialisasi Model
rf_classifier = RandomForestClassifier(random_state=42)

#Train_Model
rf_classifier.fit(X_train, y_train)

#Prediksi pada data test
y_pred_rf = rf_classifier.predict(X_test)

"""## **GradientBoosting**"""

#Inisialisasi Model
gb_classifier = GradientBoostingClassifier(random_state=42)

#Train_Model
gb_classifier.fit(X_train, y_train)

#Prediksi data test
y_pred_gb = gb_classifier.predict(X_test)

"""## **Evaluasi Model**

### **Random Forest**
"""

accuracy_train = accuracy_score(y_train, rf_classifier.predict(X_train))
accuracy_test = accuracy_score(y_test, rf_classifier.predict(X_test))

print(f"Akurasi pada data train: {accuracy_train}")
print(f"Akurasi pada data test: {accuracy_test}")

print("\nClassification Report pada Data Test:")
print(classification_report(y_test, y_pred_rf))

# Define training set sizes
train_sizes = np.linspace(0.1, 1.0, 10)

train_sizes_abs, train_scores, test_scores = learning_curve(
    rf_classifier, X_train, y_train, train_sizes=train_sizes, cv=10, scoring='accuracy')

# Calculate mean and standard deviation of training and test scores
train_scores_mean = np.mean(train_scores, axis=1)
train_scores_std = np.std(train_scores, axis=1)
test_scores_mean = np.mean(test_scores, axis=1)
test_scores_std = np.std(test_scores, axis=1)

# Plot learning curves
plt.figure(figsize=(10, 6))
plt.fill_between(train_sizes_abs, train_scores_mean - train_scores_std,
                 train_scores_mean + train_scores_std, alpha=0.1, color="r")
plt.fill_between(train_sizes_abs, test_scores_mean - test_scores_std,
                 test_scores_mean + test_scores_std, alpha=0.1, color="g")
plt.plot(train_sizes_abs, train_scores_mean, 'o-', color="r", label="Training score")
plt.plot(train_sizes_abs, test_scores_mean, 'o-', color="g", label="Cross-validation score")
plt.xlabel("Training examples")
plt.ylabel("Score")
plt.title("Learning Curve for Random Forest Classifier")
plt.legend(loc="best")
plt.grid()
plt.show()

# Melatih model RandomForest
rf_classifier.fit(X_train, y_train)

# Memprediksi kelas menggunakan model RandomForest
y_test_predict = rf_classifier.predict(X_test)

# Inisialisasi confusion matrix
cm = confusion_matrix(y_test, y_test_predict)

# Tampilkan confusion matrix
display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=rf_classifier.classes_)
display.plot(cmap=plt.cm.Blues)
plt.title("Confusion Matrix")
plt.show()

"""## **Analisa**

Didapatkan confusion matrix pada model random forest:
- 6420 data True Negative yang berarti 6420 peminjam akan ditolak untuk diberikan pinjaman

- 1208 data True Positive berarti 1208 peminjam akan di approve untuk diberikan pinjaman

- 420 data False Negative berarti 420 orang ditolak untuk diberikan pinjaman yang sebenarnya layak untuk diberikan pinjaman

- 192 data Fale Positive berarti 192 orang yang diberikan pinjaman padahal sebenarnya tidak layak diberikan pinjaman

### **Gradient Boosting**
"""

accuracy_train = accuracy_score(y_train, gb_classifier.predict(X_train))
accuracy_test = accuracy_score(y_test, gb_classifier.predict(X_test))

print(f"Akurasi pada data train: {accuracy_train}")
print(f"Akurasi pada data test: {accuracy_test}")

print("\nClassification Report pada Data Test:")
print(classification_report(y_test, y_pred_rf))

# Define training set sizes
train_sizes = np.linspace(0.1, 1.0, 10)

train_sizes_abs, train_scores, test_scores = learning_curve(
    gb_classifier, X_train, y_train, train_sizes=train_sizes, cv=10, scoring='accuracy')

# Calculate mean and standard deviation of training and test scores
train_scores_mean = np.mean(train_scores, axis=1)
train_scores_std = np.std(train_scores, axis=1)
test_scores_mean = np.mean(test_scores, axis=1)
test_scores_std = np.std(test_scores, axis=1)

# Plot learning curves
plt.figure(figsize=(10, 6))
plt.fill_between(train_sizes_abs, train_scores_mean - train_scores_std,
                 train_scores_mean + train_scores_std, alpha=0.1, color="r")
plt.fill_between(train_sizes_abs, test_scores_mean - test_scores_std,
                 test_scores_mean + test_scores_std, alpha=0.1, color="g")
plt.plot(train_sizes_abs, train_scores_mean, 'o-', color="r", label="Training score")
plt.plot(train_sizes_abs, test_scores_mean, 'o-', color="g", label="Cross-validation score")
plt.xlabel("Training examples")
plt.ylabel("Score")
plt.title("Learning Curve for Random Forest Classifier")
plt.legend(loc="best")
plt.grid()
plt.show()

# Melatih model DecisionTree
gb_classifier.fit(X_train, y_train)

# Memprediksi kelas menggunakan model DecisionTree
y_test_predict = gb_classifier.predict(X_test)

# Inisialisasi confusion matrix
cm = confusion_matrix(y_test, y_test_predict)

# Tampilkan confusion matrix
display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=gb_classifier.classes_)
display.plot(cmap=plt.cm.Blues)
plt.title("Confusion Matrix")
plt.show()

"""## **Analisa**

Didapatkan confusion matrix pada model Gradient Boosting:
- 6409 data True Negative yang berarti 6409 peminjam akan ditolak untuk diberikan pinjaman

- 1194 data True Positive berarti 1194 peminjam akan di approve untuk diberikan pinjaman

- 434 data False Negative berarti 434 orang ditolak untuk diberikan pinjaman yang sebenarnya layak untuk diberikan pinjaman

- 203 data Fale Positive berarti 203 orang yang diberikan pinjaman padahal sebenarnya tidak layak diberikan pinjaman

## **Hyperparameter**

### **Random Forest**
"""

param_dist = {
    'n_estimators': [100, 200],
    'max_depth': [20, 30],
    'criterion': ['gini', 'entropy', 'log_loss'],
}

#Inisialiasi Model Baru
rf_classifier = RandomForestClassifier(random_state=42)

#RandomSearchCV untuk tuning
random_search = RandomizedSearchCV(estimator=rf_classifier, param_distributions=param_dist, scoring='accuracy', cv=5, n_jobs=-1)

random_search.fit(X_train, y_train)

#Parameter terbaik
best_params = random_search.best_params_
print("Parameter terbaik: ", best_params)

best_rf = RandomForestClassifier(random_state=42, **best_params)
best_rf.fit(X_train, y_train)
rf_test = best_rf.predict(X_test)

#Akurasi
accuracy = accuracy_score(y_test, rf_test)
print(f"Akurasi pada data test: {accuracy}")

#Classification Report
print("\nClassification Report pada Data Test:")
print(classification_report(y_test, rf_test))

# Melatih model DecisionTree
best_rf.fit(X_train, y_train)

# Memprediksi kelas menggunakan model DecisionTree
y_test_predict = best_rf.predict(X_test)

# Inisialisasi confusion matrix
cm = confusion_matrix(y_test, y_test_predict)

# Tampilkan confusion matrix
display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=best_rf.classes_)
display.plot(cmap=plt.cm.Blues)
plt.title("Confusion Matrix")
plt.show()

"""## **Analisa**

- 6435 True Negative, 6436 orang akan ditolak melakukan pinjaman

- 1202 True Positive, 1202 orang akan diterima untuk melakukan pinjaman

- 426 False Negative, 426 orang seharusnya layak mendapatkan pinjaman tetapi model menyatakan tidak layak

- 177 False Positive, 177 orang seharusnya ditolak dalam peminjaman, tetapi model memprediksi untuk layak diberikan pinjaman

### **Gradient Boosting**
"""

params_grid = {
    'loss': ['log_loss', 'exponential'],
    'learning_rate': [0.01, 0.1],
    'n_estimators': [100, 200],
    'max_depth': [20, 30],
}

#Inisialisasi Model Baru
gb_classifier = GradientBoostingClassifier(random_state=42)

random_search = RandomizedSearchCV(estimator=gb_classifier, param_distributions=params_grid, scoring='accuracy', cv=5, n_jobs=-1)
random_search.fit(X_train, y_train)

#Parameter terbaik
best_params = random_search.best_params_

print("Parameter terbaik: ", best_params)

best_gb = GradientBoostingClassifier(random_state=42, **best_params)
best_gb.fit(X_train, y_train)
gb_test = best_gb.predict(X_test)

#Akurasi
accuracy = accuracy_score(y_test, gb_test)
print(f"Akurasi pada data test: {accuracy}")

#Classification Report
print("\nClassification Report pada Data Test:")
print(classification_report(y_test, gb_test))