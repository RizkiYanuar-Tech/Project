{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Download Library**"
      ],
      "metadata": {
        "id": "Qv7E-86H6kcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google_play_scraper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qm1QoXU6h2e",
        "outputId": "0bc0ad8d-bce2-4d94-ebf7-71e3dce7fe18"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google_play_scraper\n",
            "  Downloading google_play_scraper-1.2.7-py3-none-any.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_play_scraper-1.2.7-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: google_play_scraper\n",
            "Successfully installed google_play_scraper-1.2.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Library**"
      ],
      "metadata": {
        "id": "LIbya9ci6oxu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "C87ID9yJ57FL"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "from google_play_scraper import reviews_all, app, Sort"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Scraping Dataset**"
      ],
      "metadata": {
        "id": "FxmzPKw86sO2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scraping = reviews_all(\n",
        "    'id.tix.android',\n",
        "    lang='id',\n",
        "    country='id',\n",
        "    sort= Sort.MOST_RELEVANT,\n",
        "    count= 10000\n",
        ")"
      ],
      "metadata": {
        "id": "JYQUjPyX6XhX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('TIX_ID REVIEWS.csv', mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['Review'])\n",
        "    for review in scraping:\n",
        "        writer.writerow([review['content']])\n",
        "\n",
        "#Import kedalam csv\n",
        "reviewsTix = pd.DataFrame(scraping)\n",
        "reviewsTix.to_csv('TIX_ID REVIEWS.csv', index=False)"
      ],
      "metadata": {
        "id": "JWVGMMvf6YxM"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}